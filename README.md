# BUMIC_rasa_chatbot_template

#### (Optional) Understand How Rasa Actually Works

https://medium.com/@Zack.hardtoname/rasa-mechanism-work-flow-simply-explained-b44e85d5a6f1

#### Installation (Please ask Zack if you have any questions at all)

1. Launch your IDE with administrative permission. 

2. It is strongly recommended [seriously] that you create a virtual environment. 

3. Enter your terminal/command prompt

4. Install dependencies by running `pip install -r requirements.txt`

5. **[Do this step only if the last step  doesn't work] Recreate a new virtual environment and run in terminal:**

   1. `	pip install rasa_nlu[spacy]`

   2. `	pip install rasa-core==0.10.4`

   3. `pip install rasa_core_sdk`

6. Install your choice language model by changing the letter "lg" to "md" or "sm". The larger the language model is, the more efficient Rasa is at recognizing sentence meanings so "lg" (about 800 mb) is preferred. For more info like other languages: https://spacy.io/models/en

   1.  `python -m spacy download en_core_web_lg`
   2.  ` python -m spacy link en_core_web_lg en`	

To find more information about individual packages from the requiements.txt you can use `pip show <packagename>.`

#### Main Files

* **bot.py: the main interface to control the bot**
  * **train_nlu: train all of the training materials in the nlu_data folder. This will include all the materials in the subfolders such as  nlu_data/test, so it may take a longer time.**
  * **test_train_nlu: train the training materials in the nlu_data/test folder. Use this if you are testing your new functions**
  * **run: to chat!**
  * **classify_intent: see how rasa "sees" a particular sentence**
  * **learn_interactive: rasa learns from conversing with you (eliminates the need to write training materials)**
  * **test_train_nlu, train_dialogue, run: do these three together consecutively**
* WeChat.py: run Rasa in WeChat (no need to run bot.py)
* domain.yml: the domain for rasa
* config.yml: the config for rasa
* policy.py：polices used in rasa
* make_training_data/scripts : used to generate training materials
* make_training_data/raw_data: data used in generating training materials
* actions.py: actions that rasa is capable of

#### How to Add New Data/Functions

1. In domain.yml, add intents, slots, entities (and optionally actions and templates)
2. Add training data to the "nlu_data/test" folder 
   - Automatically generate training data here https://rodrigopivi.github.io/Chatito/ (it uses a domain-specific language)
   - Or write it by hand at https://github.com/RasaHQ/rasa-nlu-trainer (each intent requires 10-15 examples)
3. train nlu
4. Add stories to connect actions/templates with intents in stories.md
5. train dialogue 

#### Data 

* nlu_data:  used by *train_nlu*
* dia_data: used by *train_dialogue*

#### Models

* models/nlu: generated by *train_nlu*
* models/dialogue: generated by *train_dialogue*

#### Handlers

* neo4j_scripts: connecting rasa to neo4j (ask Zack for it)
* fuzzy_match: fuzzy match queries

#### Known Problems for Conversations in Chinese  

* jieba may split wholesome entities training sentences even if they are marked as a single word https://github.com/crownpku/Rasa_NLU_Chi/issues/44

  * Solution1: migrate to Rasa_NLU_Chi
  * Solution2: add mistaken words to jieba_userdict

#### Support

​	zackL@bu.edu

#### About the Author

​	https://zackLight.com

#### Sources

* <https://medium.com/python-pandemonium/better-python-dependency-and-package-management-b5d8ea29dff1>